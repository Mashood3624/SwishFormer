<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SwishFormer for Robust Firmness and Ripeness Recognition of Fruits using Visual Tactile Imagery">
  <meta name="keywords" content="SwishFormer, Tactile, Palpation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SwishFormer: A light weight model for fruit ripeness sorting</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./website/css/bulma.min.css">
  <link rel="stylesheet" href="./website/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./website/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./website/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./website/css/index.css">
  <link rel="icon" href="./website/images/ihlab_logo.jpg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./website/js/fontawesome.all.min.js"></script>
  <script src="./website/js/bulma-carousel.min.js"></script>
  <script src="./website/js/bulma-slider.min.js"></script>
  <script src="./website/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SwishFormer for Robust Firmness and Ripeness Recognition of Fruits using Visual Tactile Imagery</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=WMcSpaAAAAAJ&hl=en">Mashood M. Mohsan</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=6ixcL4cAAAAJ&hl=en">Basma Hasanen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com.pk/citations?user=11mwy0YAAAAJ&hl=en">Taimur Hassan</a><sup>2</sup>,
            </span>
            
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=es&user=vPNmbjAAAAAJ">Muhayyuddin Ahmed</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com.pk/citations?user=G_2Xpm0AAAAJ&hl=en">Naoufel Werghi</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=MIqCjoIAAAAJ&hl=en">Lakmal Seneviratne</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=bCC3kdUAAAAJ&hl=en">Irfan Hussain</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University, UAE</span>
            <span class="author-block"><sup>2</sup>Department of Electrical, Computer and Biomedical Engineering, Abu Dhabi University, UAE</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://www.sciencedirect.com/science/article/pii/S0925521425000997"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=rfSmYwNcWEg"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Mashood3624/SwishFormer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://1drv.ms/u/s!ApqqDy-MtRnr7ZNqhgBw2g6snSRObA?e=B8JfiM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%" style="border: 1px solid black; display: block; margin: auto;">
        <source src="./website/videos/Project.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Avocado ripeness estimation using <a href="https://teal-blue-zpt3.squarespace.com/stretch-2">Hello Robot</a> equipped with 
        <a href="https://digit.ml/digit.html">DIGIT</a> sensor-based gripper
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          The accurate assessment of fruit ripeness is a critical task in the agricultural industry. It
          affects the fruit quality, shelf-life, and consumer satisfaction. Traditional methods for
          estimating fruit ripeness rely on subjective human judgment and invasive sampling
          techniques, which are both infeasible and time-consuming. This paper presents a
          novel method for estimating firmness and ripeness of fruits using their palpation motion
          encoded within the visual tactile scans. Moreover, these tactile scans are passed to the
          proposed SwishFormer model coupled with Random Forest head to predict the fruits
          firmness, which is later used in classifying the fruits ripeness stage. SwishFormer,
          unlike the existing state-of-the-art models, encompasses hardswish activation as a
          token mixer which allows it to generate distinctive set of features from the candidate
          tactile scans. These rich feature representations are then fed to the Random Forest
          regressor to robustly estimate the fruit firmness values and the estimated firmness
          values are then used in accurately predicting the ripeness level of the fruits. Apart from
          this, SwishFormer is extensively evaluated on the proposed dataset, containing the
          palpation visual tactile scans, and ,<b>it outperforms state-of-the-art works by achieving
          4.77%, 4.09%, 13.69%, and 4.65% better performance in terms of MSE, RMSE, R2,
          and MAE scores, while possessing 2.02 times less parameters, and 2.09 times lesser
          GMACs</b>. Additionally, the ripeness recognition performance of the proposed system is
          thoroughly tested through real-world experiments using a Stretch Robot, where it
          achieves a success rate of 96.6%, 98.3%, and 93.3% for recognizing avocados as
          underripe, ripe, and overripe, respectively. To the best of our knowledge, this paper
          introduces a first non-destructive approach to estimate fruit firmness and ripeness
          using off-the-shelf vision-based tactile information.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Overall Architecture</h2>
        <div class="column content has-text-justified">
            <img src="./website/images/overall.png"
            class="interpolation-image"
            alt="Interpolate start reference image." style="border: 0px solid black; display: block; margin: auto;"/>
            <p>DIGIT sensor-based gripper palpates an avocado or kiwi after grasping. Three consecutive images are fed as 
              input to the proposed SwishFormer model that generate distinct feature representations. These features are 
              then concatenated together and are used in predicting the fruit firmness using random forest. The predicted 
              firmness are then compared with the standard fruit firmness thresholds to determine their ripeness levels.</p>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">DIGIT-Based Tactile Gripper</h2>
          <p>
            A custom-designed robotic gripper integrated with a DIGIT tactile sensor for non-destructive fruit firmness estimation.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./website/videos/Gripper_CAD.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">HardSwish Token Mixer</h2>
        <div class="columns is-centered">
          <div class="column content has-text-justified">
            <p>
              (a) Original Transformer architecture, (b) Metaformer: A general architecture abstracted from the 
              transformer architecture, (c) SwishFormer: The proposed architecture in which HardSwish activation function 
              is used as a token mixer.
            </p>
            <img src="./website/images/archi.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Dataset</h2>

        <div class="content has-text-justified">
          <p>
            Some random samples from the proposed dataset. The left column 
            in each pair represents the RGB image of kiwi and avocado fruits, while the right
             column shows their corresponding VBTS palpation scans obtained using a DIGIT. The RGB images lack visual cues 
             related to fruit ripeness, whereas the tactile palpation encode valuable palpation information for firmness estimation.
              The dataset also includes ground truth firmness values measured using a penetrometer, serving as a benchmark for 
              future works. The total size of the dataset is <b>4,760 sets of frames</b> along with penetrometer readings.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./website/images/RGB_DIGIT_compare_2.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->


    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>

        <div class="content has-text-justified">
          <p>
            Performance evaluation of the proposed model with state-of-the-art architectures in 
            terms of MSE, RMSE, R2, and MAE. Bold indicates the best performance, while the second-best performance is underlined.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./website/images/Results.png"
                class="interpolation-image"
                alt="Interpolate start reference image."/>
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Youtube Video</h2>
        <div class="content has-text-centered">
          <iframe width="700" height="515" src="https://www.youtube.com/embed/rfSmYwNcWEg?si=tKvTcTtFm8psir7a"
           title="YouTube video player" frameborder="0" 
           allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
           referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{mohsan2025swishformer,
      title={SwishFormer for robust firmness and ripeness recognition of fruits using visual tactile imagery},
      author={Mohsan, Mashood M and Hasanen, Basma B and Hassan, Taimur and Din, Muhayy Ud and Werghi, Naoufel and Seneviratne, Lakmal and Hussain, Irfan},
      journal={Postharvest Biology and Technology},
      volume={225}, 
      pages={113487},
      year={2025},
      publisher={Elsevier}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://www.sciencedirect.com/science/article/pii/S0925521425000997">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/Mashood3624/SwishFormer" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
              Website source code based on the Nerfies project page. If you want to reuse their <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
